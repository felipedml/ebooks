# Guia do Step de IA DinÃ¢mico

## ğŸ“š VisÃ£o Geral

O **Step de IA** permite que vocÃª gere conteÃºdo dinÃ¢mico nos seus fluxos usando modelos de linguagem (LLMs). A IA pode ler todas as respostas anteriores do usuÃ¡rio e gerar:

- **Texto**: Mensagens personalizadas
- **BotÃµes**: OpÃ§Ãµes dinÃ¢micas baseadas no contexto
- **Input**: Campos de entrada adaptados
- **OpÃ§Ãµes**: Listas de seleÃ§Ã£o contextuais

## ğŸ¯ Como Funciona

1. **Coleta Contexto**: A IA recebe todas as variÃ¡veis e respostas anteriores
2. **Processa Prompt**: Substitui variÃ¡veis `{nome_variavel}` no seu prompt
3. **Gera Output**: Usa AI SDK v5+ com structured outputs (Zod schemas)
4. **Exibe ao UsuÃ¡rio**: Renderiza o conteÃºdo gerado no fluxo

## ğŸ”§ ConfiguraÃ§Ã£o

### 1. VariÃ¡veis de Ambiente

Adicione ao seu `.env.local`:

```bash
# OpenAI
OPENAI_API_KEY=sk-your-api-key-here

# Google Gemini
GOOGLE_API_KEY=your-google-gemini-api-key-here

### 2. Criar Step de IA

Na interface `/config`:

1. Selecione um fluxo
2. Clique em "Novo Step"
3. Escolha **"AI DinÃ¢mico"**
4. Configure:
   - **Provider**: OpenAI ou Google Gemini
   - **Modelo**: 
     - OpenAI: `gpt-4o` (padrÃ£o), `gpt-4o-mini`, `gpt-4-turbo`
     - Gemini: `gemini-2.0-flash-exp` (padrÃ£o), `gemini-1.5-pro`
   - **Tipo de Output**: text, buttons, input ou options
   - **Prompt**: InstruÃ§Ã£o para a IA (pode usar variÃ¡veis)
   - **Temperature**: 0 (preciso) a 2 (criativo)

## ğŸ’¡ Exemplos PrÃ¡ticos

### Exemplo 1: Mensagem Personalizada

**Contexto**: UsuÃ¡rio informou nome e interesse

**Prompt**:
```
Com base no nome {nome} e interesse em {interesse}, 
crie uma mensagem de boas-vindas calorosa e personalizada 
oferecendo produtos relacionados ao interesse dele.
```

**Output Type**: `text`

**Resultado**:
> "OlÃ¡ JoÃ£o! Vi que vocÃª se interessa por programaÃ§Ã£o. 
> Temos cursos incrÃ­veis de Python, JavaScript e DevOps 
> que vÃ£o acelerar sua carreira. Quer conhecer?"

---

### Exemplo 2: BotÃµes DinÃ¢micos

**Contexto**: UsuÃ¡rio escolheu categoria "Tecnologia"

**Prompt**:
```
O usuÃ¡rio se interessou pela categoria {categoria}.
Gere 3-5 subcategorias relevantes como opÃ§Ãµes de botÃ£o.
Use labels curtos e atrativos.
```

**Output Type**: `buttons`

**Resultado**:
```json
{
  "buttons": [
    { "id": "1", "label": "IA & Machine Learning", "value": "ai_ml" },
    { "id": "2", "label": "Desenvolvimento Web", "value": "web_dev" },
    { "id": "3", "label": "DevOps & Cloud", "value": "devops" },
    { "id": "4", "label": "Mobile Apps", "value": "mobile" }
  ]
}
```

---

### Exemplo 3: Input Contextual

**Contexto**: UsuÃ¡rio quer feedback sobre produto X

**Prompt**:
```
O usuÃ¡rio quer dar feedback sobre {produto_nome}.
Crie um campo de input apropriado para coletar 
opiniÃ£o detalhada com placeholder relevante.
```

**Output Type**: `input`

**Resultado**:
```json
{
  "placeholder": "Como foi sua experiÃªncia com o Curso de React? Conte os detalhes...",
  "inputType": "textarea"
}
```

---

### Exemplo 4: RecomendaÃ§Ãµes

**Contexto**: UsuÃ¡rio tem nÃ­vel de experiÃªncia e orÃ§amento

**Prompt**:
```
UsuÃ¡rio: nÃ­vel {nivel_experiencia}, orÃ§amento {orcamento}.
Gere uma lista de 3-5 cursos recomendados como opÃ§Ãµes.
Seja especÃ­fico e relevante ao perfil.
```

**Output Type**: `options`

**Resultado**:
```json
{
  "options": [
    "React do Zero ao AvanÃ§ado - R$ 197",
    "Node.js para Iniciantes - R$ 147",
    "Git & GitHub Essencial - R$ 97"
  ]
}
```

## ğŸ¨ Uso de VariÃ¡veis

### VariÃ¡veis DisponÃ­veis

A IA tem acesso a:

- **VariÃ¡veis nomeadas**: Campos input com `variable` definido
- **Respostas de steps**: `step-0`, `step-1`, etc.
- **SeleÃ§Ãµes**: Valores de botÃµes e opÃ§Ãµes escolhidos

### Sintaxe

Use `{nome_variavel}` no prompt:

```
OlÃ¡ {nome}!
VocÃª escolheu {interesse}.
Sua experiÃªncia Ã© {nivel}.
```

### VariÃ¡veis Complexas

VocÃª pode referenciar toda a conversa:

```
Com base em toda a conversa anterior:
{step-0}: nome
{step-1}: interesse  
{step-2}: objetivo

Gere uma proposta personalizada de curso.
```

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Temperature

- **0.0 - 0.3**: Respostas consistentes e precisas
- **0.4 - 0.7**: Balanceado (padrÃ£o: 0.7)
- **0.8 - 1.5**: Criativo e variado
- **1.6 - 2.0**: Muito criativo (pode ser imprevisÃ­vel)

### Modelos DisponÃ­veis

**OpenAI**:
- `gpt-4o`: Mais inteligente e capaz (padrÃ£o OpenAI)
- `gpt-4o-mini`: Mais rÃ¡pido e econÃ´mico
- `gpt-4-turbo`: VersÃ£o anterior, ainda poderoso
- `gpt-3.5-turbo`: Mais barato, menos capaz

**Google Gemini**:
- `gemini-2.0-flash-exp`: Mais rÃ¡pido e eficiente (padrÃ£o Gemini) âš¡
- `gemini-1.5-pro`: Mais capaz e inteligente
- `gemini-1.5-flash`: VersÃ£o rÃ¡pida 1.5

## ğŸ” Como a IA Funciona (TÃ©cnico)

### AI SDK v5+ com Structured Outputs

```typescript
import { generateObject } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

// Schema Zod para validaÃ§Ã£o
const schema = z.object({
  type: z.literal('text'),
  content: z.string()
});

// Gera output estruturado
const result = await generateObject({
  model: openai('gpt-4o'),
  schema,
  prompt: processedPrompt,
  temperature: 0.7
});
```

### Fluxo de Processamento

1. **Inngest recebe step AI**
2. **`processAIStep()`** Ã© chamado com:
   - Provider (openai/gemini)
   - Modelo
   - Prompt com variÃ¡veis
   - Todas as respostas anteriores
3. **Substitui variÃ¡veis** no prompt
4. **Chama AI SDK** com schema apropriado
5. **Valida output** com Zod
6. **Envia evento** para FlowRunner exibir

### Tratamento de Erros

Se a IA falhar, fallbacks sÃ£o fornecidos:

- **Text**: "Desculpe, nÃ£o foi possÃ­vel processar..."
- **Buttons**: BotÃ£o "Continuar"
- **Input**: Input genÃ©rico de texto
- **Options**: ["Sim", "NÃ£o"]

## ğŸ“Š Boas PrÃ¡ticas

### âœ… FaÃ§a

- Use prompts claros e especÃ­ficos
- Mencione o contexto disponÃ­vel
- Especifique o formato desejado
- Teste com diferentes variÃ¡veis
- Use temperature baixo para consistÃªncia

### âŒ Evite

- Prompts vagos ou genÃ©ricos
- Referenciar variÃ¡veis que nÃ£o existem
- Temperature alto em produÃ§Ã£o
- Prompts muito longos (> 1000 tokens)
- Depender 100% da IA sem fallback

## ğŸš€ Casos de Uso

1. **E-commerce**: RecomendaÃ§Ãµes de produtos personalizadas
2. **EducaÃ§Ã£o**: SugestÃµes de cursos baseadas no perfil
3. **Atendimento**: Respostas adaptadas ao problema
4. **Vendas**: Propostas customizadas por lead
5. **Onboarding**: Fluxos que se adaptam ao usuÃ¡rio

## ğŸ› ï¸ Troubleshooting

### "AI step nÃ£o funciona"

- âœ… Verifique `OPENAI_API_KEY` no `.env.local`
- âœ… Confirme que a API key Ã© vÃ¡lida
- âœ… Check logs do Inngest Dashboard

### "Output inconsistente"

- Reduza temperature (0.3 - 0.5)
- Seja mais especÃ­fico no prompt
- Adicione exemplos no prompt

### "Timeout na IA"

- Simplifique o prompt
- Use modelo mais rÃ¡pido (gpt-4o-mini)
- Verifique limites da API

## ğŸ“š Recursos

- [AI SDK Documentation](https://sdk.vercel.ai/docs)
- [Structured Outputs Guide](https://sdk.vercel.ai/docs/guides/structured-outputs)
- [Zod Schema Validation](https://zod.dev/)

## ğŸ”® Roadmap

- [x] âœ… Suporte Gemini 2.0
- [ ] Suporte Anthropic Claude
- [ ] Cache de respostas similares
- [ ] AnÃ¡lise de custos por step
- [ ] Testes A/B de prompts
- [ ] Fallback inteligente entre modelos
